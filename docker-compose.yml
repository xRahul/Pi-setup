services:


  tailscale:
    image: tailscale/tailscale:v1.80
    container_name: tailscale
    restart: unless-stopped
    environment:
      - TS_AUTHKEY=${TAILSCALE_AUTH_KEY}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
      - TS_HOSTNAME=win-docker-ts
      - TS_ROUTES=10.8.1.0/24
      - TS_EXTRA_ARGS=${TS_EXTRA_ARGS}
    volumes:
      - ${TAILSCALE_PATH}:/var/lib/tailscale
    devices:
      - /dev/net/tun:/dev/net/tun
    sysctls:
      - net.ipv4.ip_forward=1
      - net.ipv6.conf.all.forwarding=1
      - net.ipv4.conf.all.src_valid_mark=1
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    networks:
      wg-easy:
        ipv4_address: 10.8.1.48



  pihole:
    image: pihole/pihole:2025.02.6
    container_name: pihole
    hostname: pihole
    restart: unless-stopped
    environment:
      # ⚠️ Change the Web UI Password:
      - WEBPASSWORD=${PIHOLE__WEBPASSWORD}
      - FTLCONF_webserver_api_password=${PIHOLE__WEBPASSWORD}
      - TZ=${DEFAULT_TZ}
    volumes:
      - ${PIHOLE_ETC_PATH}:/etc/pihole
      - ${PIHOLE_ETC_DNSMASQ_PATH}:/etc/dnsmasq.d
    # ports:
      # - "53:53/tcp"
      # - "53:53/udp"
      # - "5353:80/tcp"
    networks:
      wg-easy:
        ipv4_address: 10.8.1.3



  cloudflared-dns:
    image: cloudflare/cloudflared:2025.2.0
    container_name: cloudflared-dns-tunnel
    hostname: cloudflareddnstunnel
    user: 1000:1000 # should be owner of volumes
    restart: unless-stopped
    command: proxy-dns
    environment:
      TUNNEL_DNS_UPSTREAM: "https://1.0.0.1/dns-query,https://1.1.1.1/dns-query"
      # Listen on an unprivileged port
      TUNNEL_DNS_PORT: 5053
      # Listen on all interfaces
      TUNNEL_DNS_ADDRESS: "0.0.0.0"
      # Tunnel metrics
      TUNNEL_METRICS: 10.8.1.4:43697
    volumes:
      - ${CLOUDFALRED_DNS_PATH}:/etc/cloudflared
    # ports:
      # - "43697:43697/tcp"
    networks:
      wg-easy:
        ipv4_address: 10.8.1.4



  caddy:
    image: ghcr.io/caddybuilds/caddy-cloudflare:2.9.1
    container_name: caddy-cloudflare-web-server
    hostname: caddycloudflarewebserver
    user: 1000:1000 # should be owner of volumes
    restart: unless-stopped
    cap_add:
      - NET_ADMIN
    environment:
      - CLOUDFLARE_API_TOKEN=${CLOUDFLARE_API_TOKEN}
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ${CADDY_SITE_PATH}:/srv
      - ${CADDY_DATA_PATH}:/data
      - ${CADDY_CONFIG_PATH}:/config
    networks:
      wg-easy:
        ipv4_address: 10.8.1.5



  immich-server:
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    container_name: immich_server
    hostname: immichserver
    user: 1000:1000 # should be owner of volumes
    restart: unless-stopped
    volumes:
      - ${UPLOAD_LOCATION}:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - ./.immich_env
    healthcheck:
      disable: false
    # ports:
      # - 2283:3001
    depends_on:
      - immich_redis
      - immich_database
    networks:
      wg-easy:
        ipv4_address: 10.8.1.6



  immich-machine-learning:
    container_name: immich_machine_learning
    hostname: immichmachinelearning
    restart: always
    user: 1000:1000 # should be owner of volumes
    # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
    #   file: ./immich/hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    volumes:
      - ${ML_MODEL_CACHE_LOCATION}:/cache
    env_file:
      - ./.immich_env
    healthcheck:
      disable: false
    networks:
      wg-easy:
        ipv4_address: 10.8.1.8



  immich_redis:
    image: docker.io/redis:6.2-alpine@sha256:eaba718fecd1196d88533de7ba49bf903ad33664a92debb24660a922ecd9cac8
    container_name: immich_redis
    restart: unless-stopped
    healthcheck:
      test: redis-cli ping || exit 1
    hostname: redis
    env_file:
      - .immich_env
    volumes:
      - ${IMMICH_REDIS_DATA_PATH}:/data
    networks:
      wg-easy:
        ipv4_address: 10.8.1.9



  immich_database:
    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    container_name: immich_postgres
    restart: unless-stopped
    hostname: database
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
    env_file:
      - ./.immich_env
    volumes:
      - ${DB_DATA_LOCATION}:/var/lib/postgresql/data
    healthcheck:
      test: >-
        pg_isready --dbname="$${POSTGRES_DB}" --username="$${POSTGRES_USER}" || exit 1;
        Chksum="$$(psql --dbname="$${POSTGRES_DB}" --username="$${POSTGRES_USER}" --tuples-only --no-align
        --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')";
        echo "checksum failure count is $$Chksum";
        [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m
    command: >-
      postgres
      -c shared_preload_libraries=vectors.so
      -c 'search_path="$$user", public, vectors'
      -c logging_collector=on
      -c max_wal_size=2GB
      -c shared_buffers=512MB
      -c wal_compression=on
    networks:
      wg-easy:
        ipv4_address: 10.8.1.10




  gluetun:
    image: qmcgaw/gluetun:v3.40.0
    container_name: gluetun
    restart: unless-stopped
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    volumes:
      - ${GLUETUN_DATA_SOURCE}:/gluetun
    environment:
      TZ: ${DEFAULT_TZ}
      # Wireguard
      VPN_SERVICE_PROVIDER: surfshark
      VPN_TYPE: wireguard
      WIREGUARD_PRIVATE_KEY: ${SURFSHARK_WG_PRIVATE_KEY}
      WIREGUARD_ADDRESSES: ${WIREGUARD_ADDRESSES}
      SERVER_COUNTRIES: ${SURFSHARK_SERVER_COUNTRIES}
      # # OpenVPN
      # VPN_SERVICE_PROVIDER: nordvpn
      # VPN_TYPE: openvpn
      # OPENVPN_USER: $NORDVPN_USERNAME
      # OPENVPN_USER: $NORDVPN_PASSWORD
    # ports:
    #   - 9091:9091
    #   - 51413:51413/udp
    #   - 51413:51413
    networks:
      wg-easy:
        ipv4_address: 10.8.1.23



  transmission:
    image: linuxserver/transmission:4.0.6
    container_name: transmission
    restart: unless-stopped
    network_mode: "service:gluetun"
    volumes:
      - ${TRANSMISSION_CONFIG_SOURCE}:/config
      - ${TRANSMISSION_DOWNLOAD_SOURCE}:/downloads
      - ${TRANSMISSION_WATCH_SOURCE}:/watch
    environment:
      - PGID=1000
      - PUID=1000
      - TZ=${DEFAULT_TZ}
      # - DOCKER_MODS=linuxserver/mods:transmission-floodui
      - DOCKER_MODS=linuxserver/mods:transmission-transmissionic
      - USER=${TRANSMISSION_USERNAME}
      - PASS=${TRANSMISSION_PASSWORD}



  miniflux:
    image: miniflux/miniflux:2.2.6
    container_name: miniflux
    restart: unless-stopped
    # ports:
    #   - "80:8080"
    depends_on:
      miniflux_db:
        condition: service_healthy
    environment:
      - DATABASE_URL=${MINIFLUX_DB_URL}
      - RUN_MIGRATIONS=1
      - CREATE_ADMIN=1
      - ADMIN_USERNAME=${MINIFLUX_ADMIN_USER}
      - ADMIN_PASSWORD=${MINIFLUX_ADMIN_PASS}
      - POLLING_FREQUENCY=120
      - POLLING_SCHEDULER=entry_frequency
      - SCHEDULER_ENTRY_FREQUENCY_MAX_INTERVAL=1440
      - SCHEDULER_ENTRY_FREQUENCY_MIN_INTERVAL=120
      - SCHEDULER_ROUND_ROBIN_MIN_INTERVAL=120
      - CLEANUP_ARCHIVE_READ_DAYS=0
      - CLEANUP_ARCHIVE_UNREAD_DAYS=-1
      - WEBAUTHN=true
      - BASE_URL=https://miniflux.pi.rahulja.in
      - DATABASE_MIN_CONNS=0
      - DATABASE_CONNECTION_LIFETIME=1
    healthcheck:
      test: ["CMD", "/usr/bin/miniflux", "-healthcheck", "auto"]
      interval: 10m
    dns:
      - 10.8.1.3
      - 1.1.1.1
      - 8.8.8.8
    networks:
      wg-easy:
        ipv4_address: 10.8.1.28


  miniflux_db:
    image: postgres:17-alpine3.21
    container_name: miniflux-db
    hostname: minifluxdbhost
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${MINIFLUX_DB_USER}
      - POSTGRES_PASSWORD=${MINIFLUX_DB_PASS}
      - POSTGRES_DB=${MINIFLUX_DB_NAME}
    volumes:
      - ${MINIFLUX_DB_DATA_PATH}:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "$$MINIFLUX_DB_USER"]
      interval: 20s
      start_period: 30s
    networks:
      wg-easy:
        ipv4_address: 10.8.1.29


  paperless-ngx:
    image: ghcr.io/paperless-ngx/paperless-ngx:2.14.7
    container_name: paperless-ngx
    restart: unless-stopped
    depends_on:
      - immich_redis
    # ports:
    #   - "8000:8000"
    volumes:
      - ${PAPERLESS_NGX_DATA_PATH}:/usr/src/paperless/data
      - ${PAPERLESS_NGX_MEDIA_PATH}:/usr/src/paperless/media
      - ${PAPERLESS_NGX_EXPORT_PATH}:/usr/src/paperless/export
      - ${PAPERLESS_NGX_CONSUME_PATH}:/usr/src/paperless/consume
    environment:
      PAPERLESS_REDIS: redis://redis:6379
      PAPERLESS_TIME_ZONE: ${DEFAULT_TZ}
      PAPERLESS_URL: ${PAPERLESS_NGX_URL}
      PAPERLESS_SECRET_KEY: ${PAPERLESS_NGX_SECRET_KEY}
    dns:
      - 10.8.1.3
      - 1.1.1.1
      - 8.8.8.8
    networks:
      wg-easy:
        ipv4_address: 10.8.1.32


  filebrowser:
    image: filebrowser/filebrowser:v2.32.0-s6
    container_name: filebrowser
    volumes:
      - ${FILEBROWSER_ROOT_PATH}:/srv
      - ${FILEBROWSER_DB_FILE_PATH}:/database/filebrowser.db
      - ${FILEBROWSER_CONFIG_SETTING_FILE_PATH}:/config/settings.json
    environment:
      - PUID=1000
      - PGID=1000
    # ports:
    #   - 8080:80
    restart: unless-stopped
    dns:
      - 10.8.1.3
      - 1.1.1.1
      - 8.8.8.8
    networks:
      wg-easy:
        ipv4_address: 10.8.1.34



  memos:
    image: neosmemo/memos:0.24.0
    container_name: memos
    restart: unless-stopped
    volumes:
      - ${MEMOS_DATA_PATH}:/var/opt/memos
    # ports:
    #   - 5230:5230
    dns:
      - 10.8.1.3
      - 1.1.1.1
      - 8.8.8.8
    networks:
      wg-easy:
        ipv4_address: 10.8.1.41



  vikunja:
    image: vikunja/vikunja:0.24.6
    container_name: vikunja
    environment:
      VIKUNJA_SERVICE_JWTSECRET: ${VIKUNJA_JWTSECRET}
      VIKUNJA_SERVICE_PUBLICURL: https://vikunja.pi.rahulja.in/
      # Note the default path is /app/vikunja/vikunja.db.
      # This config variable moves it to a different folder so you can use a volume and
      # store the database file outside the container so state is persisted even if the container is destroyed.
      VIKUNJA_DATABASE_PATH: /db/vikunja.db
    # ports:
    #   - 3456:3456
    volumes:
      - ${VIKUNJA_FILES_PATH}:/app/vikunja/files
      - ${VIKUNJA_DB_PATH}:/db
    restart: always
    dns:
      - 10.8.1.3
      - 1.1.1.1
      - 8.8.8.8
    networks:
      wg-easy:
        ipv4_address: 10.8.1.46







# Booked 10.8.1.2 - 10.8.1.48

networks:
  wg-easy:
    ipam:
      config:
        - subnet: 10.8.1.0/24
